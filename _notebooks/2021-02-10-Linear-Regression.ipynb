{
 "cells": [
  {
   "source": [
    "# Linear Regression\n",
    "> Linear Regression from scratch\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Machine Learning]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Regression** is a set of methods for estimating the relationships between a `outcome variable` and `features`.\n",
    "\n",
    "When our input consist of d features, we express our prediction $\\hat{y}$ as \n",
    "$$\\hat{y} = w_1  x_1 + ... + w_d  x_d + b$$\n",
    "\n",
    "Collecting all features into a vector $\\mathbf{x} \\in \\mathbb{R}^d$ and all weights into a vector $\\mathbf{w} \\in \\mathbb{R}^d$, we can express our model compacity using a dot product:\n",
    "$$ \\hat{y} = \\mathbf{w}^T\\mathbf{x} +b$$\n",
    "\n",
    "The vector $\\mathbb{x}$ corresponds to features of a single data example. To represent tho whole dataset we use $\\mathbf{X} \\in \\mathbb{R}^{n\\times d}$. Here $\\mathbf{X}$ contains one row for every example and one column for every feature. The predictions $\\mathbf{\\hat{y}} \\in \\mathbb{R}^n$ can be expressed as: \n",
    "$$ \\mathbf{\\hat{y}} = \\mathbf{Xw} +b$$\n",
    "\n",
    "The `Loss function` quantifies the distance between the real and predicted value of the target.\n",
    "$$ (y - \\hat{y})^2 =  \\|\\mathbf{y} - \\mathbf{X}\\mathbf{w}\\|^2 $$\n",
    "\n",
    "We need to find $\\mathbf{w}$ to minimize the loss function. The analytic solution is:\n",
    " $$ (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X^T}\\mathbf{y}$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  \n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    X = tf.zeros((num_examples, w.shape[0]))\n",
    "    X += tf.random.normal(shape=X.shape)\n",
    "    y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b\n",
    "    y += tf.random.normal(shape=y.shape, stddev=0.01)\n",
    "    y = tf.reshape(y, (-1, 1))\n",
    "    return X, y\n",
    "\n",
    "true_w = tf.constant([2, -3.4])\n",
    "true_b = 4.2\n",
    "X, y = synthetic_data(true_w, true_b, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(X, y):\n",
    "    X = tf.concat([X,tf.ones(y.shape)],1)\n",
    "    A = tf.linalg.inv(tf.matmul(tf.transpose(X),X))\n",
    "    B = tf.matmul(tf.transpose(X),y)\n",
    "    return tf.matmul(A,B)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[ 1.9995857],\n",
       "       [-3.4000173],\n",
       "       [ 4.2007246]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "solution(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}